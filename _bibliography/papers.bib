---
---
@article{teneggi2023weakly,
  title    = {Examination-level Supervision for Deep Learning-Based Intracranial Hemorrhage Detection on Head CT},
  author   = {Teneggi, Jacopo and Yi, Paul H. and Sulam, Jeremias},
  journal  = {Radiology: Artificial Intelligence},
  year     = {2023},
  selected = {true},
  abbr     = {Rad AI},
  date     = {Dec. 5, 2023},
  url      = {},
  abstract = {Purpose. To compare the effectiveness of weak supervision (i.e., with examination-level labels only) and strong supervision (i.e., with image-level labels) in training deep learning (DL) models for detection of intracranial hemorrhage (ICH) on head CT.
  Materials and Methods. In this retrospective study, an attention-based convolutional neural network was trained with either local (i.e., image-level) or global (i.e., examination-level) binary labels on the Radiological Society of North America (RSNA) 2019 Brain CT Hemorrhage Challenge dataset of 21,784 exams (41% ICH) and 752,803 images (14% ICH). The CQ500 (436 exams, 49% ICH) and CT-ICH (75 exams, 48% ICH) datasets were employed for external testing. Performance in detecting ICH was compared between weak (examination-level labels) and strong (image-level labels) learners as a function of the number of labels available during training. 
  Results. On examination-level binary classification, weak and strong learners did not have different area under the receiver operating characteristic curve values on the internal validation split (0.96 vs. 0.96, p=0.64) and the CQ500 dataset (0.95 vs. 0.92, p=0.15). Weak learners outperformed strong ones on the CT-ICH dataset (0.92 vs. 0.90, p=0.03). Weak learners had better slice-level ICH detection performance when more than 10,000 labels were available for training (average , 0.73 vs 0.65, ùëì1 p<0.001). Weaklysupervised models trained on the entire RSNA dataset required 35 times fewer labels than equivalent strong learners. 
  Conclusion. Strongly-supervised models did not achieve better performance than weakly-supervised ones, which could dramatically reduce radiologist labor requirements for prospective dataset curation.}
}

@article{teneggi2022shapxrt,
  title    = {SHAP-XRT: The Shapley Value Meets Conditional Independence Testing},
  author   = {Teneggi, Jacopo* and Bharti, Beepul* and Romano, Yaniv and Sulam, Jeremias},
  journal  = {Transactions on Machine Learning Research},
  year     = {2023},
  selected = {true},
  abbr     = {TMLR},
  url      = {https://openreview.net/forum?id=WFtTpQ47A7},
  abstract = {The complex nature of artificial neural networks raises concerns on their reliability, trustworthiness, and fairness in real-world scenarios. The Shapley value---a solution concept from game theory---is one of the most popular explanation methods for machine learning models. More traditionally, from a statistical perspective, feature importance is defined in terms of conditional independence. So far, these two approaches to interpretability and feature importance have been considered separate and distinct. In this work, we show that Shapley-based explanation methods and conditional independence testing are closely related. We introduce the SHAPley EXplanation Randomization Test (SHAP-XRT), a testing procedure inspired by the Conditional Randomization Test (CRT) for a specific notion of local (i.e., on a sample) conditional independence. With it, we prove that for binary classification problems, the marginal contributions in the Shapley value provide lower and upper bounds to the expected p-values of their respective tests. Furthermore, we show that the Shapley value itself provides an upper bound to the expected p-value of a global (i.e., overall) null hypothesis. As a result, we further our understanding of Shapley-based explanation methods from a novel perspective and characterize the conditions under which one can make statistically valid claims about feature importance via the Shapley value.}
}

@article{teneggi2023trust,
  title        = {How to Trust Your Diffusion model: A Convex Optimization Approach to Conformal Risk Control},
  author       = {Teneggi, Jacopo and Tivnan, Matthew and Stayman, Web and Sulam, Jeremias},
  booktitle    = {International Conference on Machine Learning},
  pages        = {33940--33960},
  year         = {2023},
  organization = {PMLR},
  selected     = {true},
  abbr         = {ICML},
  date         = {Jul. 23, 2023},
  abstract     = {Score-based generative modeling, informally referred to as diffusion models, continue to grow in popularity across several important domains and tasks. While they provide high-quality and diverse samples from empirical distributions, important questions remain on the reliability and trustworthiness of these sampling procedures for their responsible use in critical scenarios. Conformal prediction is a modern tool to construct finite-sample, distribution-free uncertainty guarantees for any black-box predictor. In this work, we focus on image-to-image regression tasks and we present a generalization of the Risk-Controlling Prediction Sets (RCPS) procedure, that we term K-RCPS, which allows to (i) provide entrywise calibrated intervals for future samples of any diffusion model, and (ii) control a certain notion of risk with respect to a ground truth image with minimal mean interval length. Differently from existing conformal risk control procedures, ours relies on a novel convex optimization approach that allows for multidimensional risk control while provably minimizing the mean interval length. We illustrate our approach on two real-world image denoising problems: on natural images of faces as well as on computed tomography (CT) scans of the abdomen, demonstrating state of the art performance.}
}

@article{teneggi2022fast,
  title     = {Fast Hierarchical Games for Image Explanations},
  author    = {Teneggi, Jacopo and Luster, Alexandre and Sulam, Jeremias},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2022},
  publisher = {IEEE},
  selected  = {true},
  abbr      = {TPAMI},
  date      = {Jul. 11, 2022},
  url       = {https://ieeexplore.ieee.org/document/9826424},
  abstract  = {As modern complex neural networks keep breaking records and solving harder problems, their predictions also become less and less intelligible. The current lack of interpretability often undermines the deployment of accurate machine learning tools in sensitive settings. In this work, we present a model-agnostic explanation method for image classification based on a hierarchical extension of Shapley coefficients‚ÄìHierarchical Shap (h-Shap)‚Äìthat resolves some of the limitations of current approaches. Unlike other Shapley-based explanation methods, h-Shap is scalable and can be computed without the need of approximation. Under certain distributional assumptions, such as those common in multiple instance learning, h-Shap retrieves the exact Shapley coefficients with an exponential improvement in computational complexity. We compare our hierarchical approach with popular Shapley-based and non-Shapley-based methods on a synthetic dataset, a medical imaging scenario, and a general computer vision problem, showing that h-Shap outperforms the state of the art in both accuracy and runtime. Code and experiments are made publicly available.}
}

@article{athey2021fitting,
  title     = {Fitting Splines to Axonal Arbors Quantifies Relationship Between Branch Order and Geometry},
  author    = {Athey, Thomas L and Teneggi, Jacopo and Vogelstein, Joshua T and Tward, Daniel J and Mueller, Ulrich and Miller, Michael I},
  journal   = {Frontiers in Neuroinformatics},
  pages     = {38},
  year      = {2021},
  publisher = {Frontiers},
  selected  = {true},
  abbr      = {Front Neurosci},
  date      = {Aug. 11, 2021},
  url       = {https://www.frontiersin.org/articles/10.3389/fninf.2021.704627/full},
  abstract  = {Neuromorphology is crucial to identifying neuronal subtypes and understanding learning. It is also implicated in neurological disease. However, standard morphological analysis focuses on macroscopic features such as branching frequency and connectivity between regions, and often neglects the internal geometry of neurons. In this work, we treat neuron trace points as a sampling of differentiable curves and fit them with a set of branching B-splines. We designed our representation with the Frenet-Serret formulas from differential gemoetry in mind. The Frenet-Serret formulas completely characterize smooth curves, and involve two parameters, curvature and torsion. Our representation makes it possible to compute these parameters from neuron traces in closed form. These parameters are defined continuously along the curve, in contrast to other parameters like tortuosity which depend on start and end points. We applied our method to a dataset of cortical projection neurons traced in two mouse brains, and found that the parameters are distributed differently between primary, collateral, and terminal axon branches, thus quantifying geometric differences between different components of an axonal arbor. The results agreed in both brains, further validating our representation. The code used in this work can be readily applied to neuron traces in SWC format and is available in our open-source Python package brainlit: http://brainlit.neurodata.io/.}
}

@article{teneggi2021entropy,
  title     = {Entropy estimation within in vitro neural-astrocyte networks as a measure of development instability},
  author    = {Teneggi, Jacopo and Chen, Xin and Balu, Alan and Barrett, Connor and Grisolia, Giulia and Lucia, Umberto and Dzakpasu, Rhonda},
  journal   = {Physical Review E},
  volume    = {103},
  number    = {4},
  pages     = {042412},
  year      = {2021},
  publisher = {APS},
  selected  = {true},
  abbr      = {Phys Rev E},
  date      = {Apr. 15, 2021},
  url       = {https://journals.aps.org/pre/abstract/10.1103/PhysRevE.103.042412},
  abstract  = {The brain demands a significant fraction of the energy budget in an organism; in humans, it accounts for 2% of the body mass, but utilizes 20% of the total energy metabolized. This is due to the large load required for information processing; spiking demands from neurons are high but are a key component to understanding brain functioning. Astrocytic brain cells contribute to the healthy functioning of brain circuits by mediating neuronal network energy and facilitating the formation and stabilization of synaptic connectivity. During development, spontaneous activity influences synaptic formation, shaping brain circuit construction, and adverse astrocyte mutations can lead to pathological processes impacting cognitive impairment due to inefficiencies in network spiking activity. We have developed a measure that quantifies information stability within in vitro networks consisting of mixed neural-astrocyte cells. Brain cells were harvested from mice with mutations to a gene associated with the strongest known genetic risk factor for Alzheimer's disease, APOE. We calculate energy states of the networks and using these states, we present an entropy-based measure to assess changes in information stability over time. We show that during development, stability profiles of spontaneous network activity are modified by exogenous astrocytes and that network stability, in terms of the rate of change of entropy, is allele dependent.}
}

